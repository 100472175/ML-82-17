{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93068dce9f22b25b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Project Introduction:\n",
    "Primer laboratorio de aprendizaje automático, desarrollado por Sergio Barragán Blanco (100472343) y Eduardo Alarcón Navarro (100472175). \n",
    "Grupo 17.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933f5cb4b3926278",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Problema de Clasificación\n",
    "A continuación, dividiremos la energía entre alta y baja siguiendo las instrucciones (alta si es mayor que el tercer quartil). Y entrenaremos el mejor modelo anterior para ver los resultados, posteriormente elegiremos algunos modelos de Clasificación para entrenar este nuevo problema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e738704b6e206784",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8686906c824078d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "También, vamos a importar el documento con los datos de entrenamiento, y le vamos a eliminar las columnas innecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a0bf13cf1f98b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('wind_ava.csv.gz', compression='gzip')\n",
    "\n",
    "# FIlter the data to only include the columns that end in 13\n",
    "data = data.filter(regex='13$|energy')\n",
    "#print(data)\n",
    "\n",
    "y = data['energy']\n",
    "x = data.drop(columns=['energy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e98abb555e4f64",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d318af744d9aa25a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_size vamos a escoger 0.2 ya que tenemos datos en un rango de 5 años en orden (2015-2019) por lo que (asumiendo que el numero de datos para todos los años es similar) usaremos 2019 como test final.\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False)\n",
    "#print(f\"Fechas de tain {train.iloc[0].datetime}-{train-iloc[-1].datetime}\")\n",
    "\n",
    "model = SVR(C=701, degree=2, gamma='auto', kernel='rbf', epsilon=0.1)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', PowerTransformer()),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "# Comprobamos que la RMSE sea igual que en el ejemplo anterior\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# Ahora vamos a clasificar entre alta y baja, a ver que tan preciso es\n",
    "tercer_cuartil = np.quantile(y_train, 0.75)\n",
    "\n",
    "# Asignar etiquetas\n",
    "y_test_class = np.where(y_test > tercer_cuartil, 1, 0)\n",
    "\n",
    "# Predecir valores\n",
    "y_pred_class = np.where(y_pred > tercer_cuartil, 1, 0)\n",
    "\n",
    "# Evaluar la clasificación\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "precision = precision_score(y_test_class, y_pred_class, pos_label=1)\n",
    "recall = recall_score(y_test_class, y_pred_class, pos_label=1)\n",
    "f1_alta = f1_score(y_test_class, y_pred_class, pos_label=1)\n",
    "f1_baja = f1_score(y_test_class, y_pred_class, pos_label=0)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test_class, y_pred_class)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", \"ALTA = \", f1_alta, \"BAJA = \", f1_baja)\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy)\n",
    "\n",
    "# Matriz de confusión\n",
    "confusion_matrix = pd.crosstab(y_test_class, y_pred_class, rownames=['Real'], colnames=['Predicho'])\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616304f5b8e8f474",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dado que el resultado más preciso para nuestro modelo ha sido la accuracy, la mantendremos como principal estimación para futuros modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcecc08219a0344",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Modelos que usan clasificación\n",
    "A continuación transformaremos los datos para que los valores a predecir sean de clasificación. Debido a que el PowerTransformer() no funciona bien para clasificación, en su defecto, usaremos el segundo mejor scaler, el RobustScaler().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f115f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paso 3: Entrenamiento del modelo\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "tercer_cuantil = np.quantile(y_train, 0.75)\n",
    "y_train = np.where(y_train < tercer_cuantil, 0, 1)\n",
    "y_test = np.where(y_test < tercer_cuantil, 0, 1)\n",
    "\n",
    "# 1 Alta\n",
    "# 0 Baja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595af26d8e4e2799",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Primero probaremos con el KNN Clasifier, el cual, como se puede observar, posee exactamente los mismos hiperparámetros que su contraparte de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc97d045b7d6ce8b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': range(5, 40, 5), \n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': range(1, 25, 5),\n",
    "    'p' : [1, 2]  # distance `= 1 manhattan, p=2 euclidean\n",
    "}\n",
    "\n",
    "cv = TimeSeriesSplit()\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Búsqueda de hiperparámetros\n",
    "grid_search = GridSearchCV(knn_model, param_grid, cv=cv, n_jobs=-1, scoring='f1_macro')\n",
    "without_params = GridSearchCV(knn_model,{}, cv=cv, n_jobs=-1, scoring='f1_macro')\n",
    "\n",
    "# Construcción del pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('model', grid_search)\n",
    "])\n",
    "pipe_without_params = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('model', without_params)\n",
    "])\n",
    "\n",
    "# Entrenamiento del pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe_without_params.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo y parámetros\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_model_w = without_params.best_estimator_\n",
    "best_params_w = without_params.best_params_\n",
    "\n",
    "print(\"Mejor modelo:\", best_model, \"<--------->\", best_model_w)\n",
    "print(\"Mejores parámetros:\", best_params, \"<--------->\", best_params_w)\n",
    "print(\"Score:\", grid_search.best_score_, \"<--------->\", without_params.best_score_)\n",
    "\n",
    "\"\"\"\n",
    "Mejor modelo: KNeighborsClassifier(leaf_size=1, n_neighbors=15, p=1, weights='distance') <---------> KNeighborsClassifier()\n",
    "Mejores parámetros: {'algorithm': 'auto', 'leaf_size': 1, 'n_neighbors': 15, 'p': 1, 'weights': 'distance'} <---------> {}\n",
    "Score: 0.784670463832614 <---------> 0.7742702702415876\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como hemos podido observar, el modelo con el RobustScaler da más o menos igual con y sin hiperparámetros, sin embargo 0.78 es un valor que demuestra que está aprendiendo algo."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea1ddc877d183d5f"
  },
  {
   "cell_type": "markdown",
   "id": "3d9eae371d5a49e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A continuación probaremos con un Decision Tree Classifier, el cual tambiénposee los mismos hiperparámetros que la versión de regresión, con la excepción de añadir \"classweight\", la cual será usada con el objetivo de balancear las muestras (ya que estamos dividiendo los datos en una relacción de 75%-25%) Al igual que con el modelo de regresión, también lo entrenaremos con y sin scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b4251e300523",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definir el espacio de búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],  # Criterios de desbalanceo para clasificación\n",
    "    'max_depth': [None, 10, 12, 13, 14, 15, 16, 17],\n",
    "    'min_samples_split': range(2, 15, 2),\n",
    "    'min_samples_leaf': range(1, 10, 2),\n",
    "    'class_weight': ['balanced']  \n",
    "}\n",
    "\n",
    "cv = TimeSeriesSplit()\n",
    "\n",
    "model = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=cv, n_jobs=-1, verbose=1,\n",
    "                           scoring='f1_macro')  \n",
    "\n",
    "model2 = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=cv, n_jobs=-1, verbose=1,\n",
    "                      scoring='f1_macro')\n",
    "without_params = GridSearchCV(DecisionTreeClassifier(), {}, cv=cv, n_jobs=-1, verbose=1,\n",
    "                      scoring='f1_macro')\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('model', model),\n",
    "    \n",
    "])\n",
    "pipe_without_params = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('model', without_params),\n",
    "    \n",
    "])\n",
    "\n",
    "# Entrenamiento del pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)\n",
    "pipe_without_params.fit(X_train, y_train)\n",
    "\n",
    "pipe_best_params = pipe.named_steps['model'].best_params_\n",
    "pipe_score = pipe.named_steps['model'].best_score_\n",
    "\n",
    "pipe_wp_best_params = pipe_without_params.named_steps['model'].best_params_\n",
    "pipe_wp_score = pipe_without_params.named_steps['model'].best_score_\n",
    "\n",
    "best_params = model2.best_params_\n",
    "score = model2.best_score_\n",
    "\n",
    "print(f\"Mejores parámetros: Sin scaler: {best_params} <-----> Con scaler: {pipe_best_params} <-----------> Sin HPO{pipe_wp_best_params}\")\n",
    "print(f\"Mejor puntuación: Sin scaler {score} <-----> Con scaler: {pipe_score} <-----------> Sin HPO: {pipe_wp_score}\")\n",
    "\n",
    "\"\"\"\n",
    "Mejores parámetros: Sin scaler: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 12, 'min_samples_leaf': 9, 'min_samples_split': 14} <-----> Con scaler: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 12, 'min_samples_leaf': 9, 'min_samples_split': 6} <-----------> Sin HPO{}\n",
    "Mejor puntuación: Sin scaler 0.7887936967961423 <-----> Con scaler: 0.7891987832808501 <-----------> Sin HPO: 0.7367893170622747\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como podemos observar, no hay mucha diferencia entre usar el método de escalado o no (siendo ligeramente mejor el de escalado), pero esta vez sí que tiene mas relevancia el uso de hiperparámetros."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c04a63f97226f442"
  },
  {
   "cell_type": "markdown",
   "id": "e1a7ee1fb2af7a6b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Y por último, probaremos con un SVM, ya que el mejor modelo para regresión fué su contraparte, esperamos que dé resultados similares o mejores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efec1109a5bb240",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = TimeSeriesSplit()\n",
    "\n",
    "# Instancia del modelo clasificador SVM\n",
    "model = SVC()\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'C': range(1, 50),\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [2, 3, 4, 5],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'class_weight': ['balanced'] \n",
    "}\n",
    "\n",
    "# Búsqueda de hiperparámetros\n",
    "grid_search = GridSearchCV(model,\n",
    "                                 param_grid,\n",
    "                                 cv=cv, \n",
    "                                 n_jobs=-1, \n",
    "                                 scoring='f1_macro',  # Métrica de clasificación\n",
    "                                 )\n",
    "without_params = GridSearchCV(model, {}, cv=cv, n_jobs=-1, scoring='f1_macro')\n",
    "\n",
    "# Construcción del pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('model', grid_search)\n",
    "])\n",
    "pipe_without_params = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('model', without_params)\n",
    "])\n",
    "\n",
    "# Entrenamiento del pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe_without_params.fit(X_train, y_train)\n",
    "# Obtener el mejor modelo y sus parámetros\n",
    "best_model = pipe.named_steps[\"model\"].best_estimator_\n",
    "best_params = pipe.named_steps[\"model\"].best_params_\n",
    "best_score = pipe.named_steps[\"model\"].best_score_\n",
    "\n",
    "best_model_w = pipe_without_params.named_steps[\"model\"].best_estimator_\n",
    "best_params_w = pipe_without_params.named_steps[\"model\"].best_params_\n",
    "best_score_w = pipe_without_params.named_steps[\"model\"].best_score_\n",
    "\n",
    "print(f\"Mejor modelo: Con HPO: {best_model} <-----> Sin HPO: {best_model_w}\")\n",
    "print(f\"Mejores parámetros: {best_params} <-----> Sin HPO: {best_params_w}\")\n",
    "print(f\"Score: {best_score} <-----> Sin HPO: {best_score_w}\")\n",
    "\"\"\"\n",
    "Mejor modelo: Con HPO: SVC(C=11, class_weight='balanced', degree=2, gamma='auto', kernel='poly') <-----> Sin HPO: SVC()\n",
    "Mejores parámetros: {'C': 11, 'class_weight': 'balanced', 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'} <-----> Sin HPO: {}\n",
    "Score: 0.799546415006745 <-----> Sin HPO: 0.7753889434496996\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como podemos apreciar, el modelo demuestra aprender más con el HPO, sin embargo, este método es demasidado costoso (lento), como para tenerlo en cuenta a la hora de elegirlo como el mejor modelo, por lo que en el caso de clasificación, escogeremos, que según la métrica de f1_macro, sería el DecisionTreeClassifier."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ca76e49c174eb69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Uso de ChatGPT en esta parte:\n",
    "Para esta parte, como ya poseíamos un amplio conocimento y experiencia de la parte de regresión, no hubo uso de la herramienta. Con la única excepción de intentar resolver el error que daba nan con cualquier scoring debido a que las clases estaban divididas en altas y bajas. No obstante, ChatGPT no solucionó este problema, por lo que se acabó usando la solución de los profesores (cambiar \"alta\" y \"baja\" por 0 y 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9c33c2a72f2e665"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
