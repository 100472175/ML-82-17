{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93068dce9f22b25b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Project Introduction:\n",
    "Primer laboratorio de aprendizaje automático, desarrollado por Sergio Barragán Blanco (100472343) y Eduardo Alarcón Navarro (100472175). \n",
    "Grupo 17.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA\n",
    "Existen 23 carácterísticas que definen cada momento, de las cuales ninguna es categórica, todas son numéricas (con la energía suman 24). No existen valores faltantes, pero si los hubiera, los rellenaríamos con la media del valor superior e inferior antes de randomizar el dataset.\n",
    "\n",
    "No existen tampoco columnas constantes, que se eliminarían. \n",
    "\n",
    "Con todo esto, podemos observar que es un problema de regresión.\n",
    "\n",
    "La variable que estamos intentando predecir es la \"energía\" que es el valor de la enrgía generada 24 horas después. \n",
    "\n",
    "## Correlaciones entre parámetros:\n",
    "Al principio, parece que las columnas lai_lv.13 y lai_hv.13 tienen una correlación, pero según avanza el tiempo, desaparece.\n",
    "\n",
    "## Escala de los datos\n",
    "Entre las diferentes columnas de datos, tenemos valores y magnitudes muy dispares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "718a0bf13cf1f98b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T16:44:46.099191100Z",
     "start_time": "2024-02-29T16:44:45.492428600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009999275207519531\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the data\n",
    "data = pd.read_csv('wind_ava.csv.gz', compression='gzip')\n",
    "# FIlter the data to only include the columns that end in 13\n",
    "import time\n",
    "a = time.time()\n",
    "data = data.filter(regex='13$|energy')\n",
    "#print(data)\n",
    "print(time.time()-a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data['energy']\n",
    "x = data.drop(columns=['energy'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=7543)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T16:51:23.798536400Z",
     "start_time": "2024-02-29T16:51:23.792320Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier  \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scalers = [StandardScaler(), MinMaxScaler(), RobustScaler(), Normalizer()]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), x.columns)\n",
    "    ])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T16:44:46.112876600Z",
     "start_time": "2024-02-29T16:44:46.108168700Z"
    }
   },
   "id": "4fc2e646359c0bd8"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "Best params: {'min_samples_split': 20, 'min_samples_leaf': 6, 'max_depth': 12, 'criterion': 'absolute_error'}\n"
     ]
    }
   ],
   "source": [
    "# Optimizing hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['friedman_mse', 'absolute_error', 'poisson', 'squared_error'],  # Adjust criterion for regression\n",
    "    'max_depth': [None, 12, 13, 14, 15, 16, 17],\n",
    "    'min_samples_split': range(1, 15, 2),\n",
    "    'min_samples_leaf': range(5, 15, 2),\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5)\n",
    "model2 = RandomizedSearchCV(DecisionTreeRegressor(random_state=7543),  # Use DecisionTreeRegressor\n",
    "                     param_grid, cv=cv, n_jobs=-1, verbose=1, scoring='neg_mean_absolute_percentage_error', n_iter=50)  # Adjust scoring metric\n",
    "\n",
    "model = GridSearchCV(DecisionTreeRegressor(random_state=7543),  # Use DecisionTreeRegressor\n",
    "                     param_grid, cv=cv, n_jobs=-1, verbose=1, scoring='neg_mean_absolute_percentage_error')\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(f\"Best params: {model.best_params_}\")\n",
    "# Best params: {'criterion': 'absolute_error', 'max_depth': 15, 'min_samples_leaf': 11, 'min_samples_split': 3}\n"
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T17:52:19.675611300Z",
     "start_time": "2024-02-29T17:52:19.657594700Z"
    }
   },
   "id": "48f24c60f565a7dc"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 313274.75857536943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Crear el modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) en el conjunto de prueba\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T16:47:19.411282200Z",
     "start_time": "2024-02-29T16:46:56.359671Z"
    }
   },
   "id": "f275a987e9421aae"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the model: 621.2880027885399\n"
     ]
    }
   ],
   "source": [
    "# Vamos a probar con KNN Regresor\n",
    "from sklearn import neighbors\n",
    "from sklearn import metrics\n",
    "regr = neighbors.KNeighborsRegressor()\n",
    "\n",
    "# We train it\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# We obtain predictions on the test set\n",
    "y_test_pred = regr.predict(X_test)\n",
    "\n",
    "# We compute accuracy\n",
    "rmse_knn = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "print(f\"RMSE of the model: {rmse_knn}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T16:44:53.314409800Z",
     "start_time": "2024-02-29T16:44:53.310837200Z"
    }
   },
   "id": "3823beec798adab4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
