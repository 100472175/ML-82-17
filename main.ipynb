{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93068dce9f22b25b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Project Introduction:\n",
    "Primer laboratorio de aprendizaje automático, desarrollado por Sergio Barragán Blanco (100472343) y Eduardo Alarcón Navarro (100472175). \n",
    "Grupo 17.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. EDA\n",
    "Existen 22 carácterísticas que definen cada momento, de las cuales ninguna es categórica, todas son numéricas (con la energía suman 23). No existen valores faltantes, pero si los hubiera, los rellenaríamos con la media del valor superior e inferior antes de randomizar el dataset.\n",
    "\n",
    "No existen tampoco columnas constantes, que se eliminarían. \n",
    "\n",
    "Con todo esto, podemos observar que es un problema de regresión.\n",
    "\n",
    "La variable que estamos intentando predecir es la \"energía\" que es el valor de la energía generada 24 horas después. \n",
    "\n",
    "Por lo tanto, vamos a comenzar con todos los imports necesarios para este proyecto"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "933f5cb4b3926278"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor  \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import neighbors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e738704b6e206784"
  },
  {
   "cell_type": "markdown",
   "source": [
    "También, vamos a importar el documento con los datos de entrenamiento, y le vamos a eliminar las columnas innecesarias"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8686906c824078d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a0bf13cf1f98b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('wind_ava.csv.gz', compression='gzip')\n",
    "\n",
    "# FIlter the data to only include the columns that end in 13\n",
    "data = data.filter(regex='13$|energy')\n",
    "#print(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Y separar los datos de entrenamiento de los datos de test, con train_test_split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c9742cebf2d115e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f5d899342eb290",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data['energy']\n",
    "x = data.drop(columns=['energy'])\n",
    "\n",
    "# test_size vamos a escoger 0.2 ya que tenemos datos en un rango de 5 años en orden (2015-2019) por lo que usaremos 2019 como test final.\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=7543)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4d0ecc92bc45e922"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2e646359c0bd8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier  \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "scalers = [StandardScaler(), MinMaxScaler(), RobustScaler(), Normalizer()]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), x.columns)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decidir usando KNN\n",
    "A continuación, usaremos KNN "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54e98abb555e4f64"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Entrenamiento de diferentes modelos\n",
    "Lo próximo que haremos, será probar con diferentes métodos de entrenamiento (KNN, árboles de regresión, regresión lineal normal y la variante de Lasso, y SVM. Para elegir el mejor, usaremos la librería time para saber cuánto se tarda en entrenar cada modelo, un dummy para comparar resultados, y el mejor de entre ellos, usando una política de importancia de 20% a tiempo y 80% precisión."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9dcecc08219a0344"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para empezar, vamos a probar con un Decision Tree Regresor."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "595af26d8e4e2799"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f24c60f565a7dc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimizing hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor  # Import DecisionTreeRegressor instead of DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['friedman_mse', 'absolute_error', 'poisson', 'squared_error'],  # Adjust criterion for regression\n",
    "    'max_depth': [None, 12, 13, 14, 15, 16, 17],\n",
    "    'min_samples_split': range(2, 15, 2),\n",
    "    'min_samples_leaf': range(5, 15, 2),\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5)\n",
    "model = RandomizedSearchCV(DecisionTreeRegressor(random_state=7543),  # Use DecisionTreeRegressor\n",
    "                     param_grid, cv=cv, n_jobs=-1, verbose=1, scoring='neg_mean_absolute_percentage_error', n_iter=50)  # Adjust scoring metric\n",
    "\n",
    "model2 = GridSearchCV(DecisionTreeRegressor(random_state=7543),  # Use DecisionTreeRegressor\n",
    "                     param_grid, cv=cv, n_jobs=-1, verbose=1, scoring='neg_mean_absolute_percentage_error')\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "\n",
    "rmse_tree = metrics.mean_squared_error(y_test, y_pred)\n",
    "sqrt_rmse_tree = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {rmse_tree}\")\n",
    "print(f\"SQRT RMSE: {sqrt_rmse_tree}\")\n",
    "print(f\"Best params: {model.best_params_}\")\n",
    "# Best params: {'criterion': 'absolute_error', 'max_depth': 15, 'min_samples_leaf': 11, 'min_samples_split': 3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f115f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dunny regressor to obtain a baseline\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', dummy)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "rmse_dummy = metrics.mean_squared_error(y_test, y_pred)\n",
    "sqrt_rmse_dummy = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {rmse_dummy}\")\n",
    "print(f\"SQRT RMSE: {sqrt_rmse_dummy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275a987e9421aae",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False],\n",
    "    'n_jobs': [-1],  # -1 indica utilizar todos los núcleos\n",
    "    'positive': [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "# Crear el modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "\n",
    "grid_search = GridSearchCV(model,\n",
    "                           param_grid,\n",
    "                           cv=5,\n",
    "                           scoring=\"neg_mean_absolute_percentage_error\"\n",
    "                           )\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Mejor modelo:\",best_model)\n",
    "print(\"Mejorres parámetros:\",best_params)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora que ya hemos probado con el Lineal Model normal, vamos a probar con la variante de Lasso a ver si conseguimos mejorar el entrenamiento:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3135ff92e842b77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Definir los parámetros que deseas probar\n",
    "parameters = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0],  # Valores de regularización\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False], # pendientes de borrar\n",
    "    'positive': [True, False], \n",
    "    'precompute': [True, False], \n",
    "    'random_state': [7543], \n",
    "    'selection': ['cyclic', 'random'], \n",
    "    'tol': [1**(-10), 1**(-5), 1**(-4), 1**(-3), 1**(-2)], \n",
    "    'warm_start': [True, False]\n",
    "}\n",
    "\n",
    "# Crear el modelo de regresión lineal Lasso\n",
    "model = Lasso()\n",
    "\n",
    "grid_search = GridSearchCV(model, \n",
    "                           parameters, \n",
    "                           scoring='neg_mean_squared_error', \n",
    "                           cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo y sus hiperparámetros\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Mejor modelo:\",best_model)\n",
    "print(\"Mejorres parámetros:\",best_params)\n",
    "print(\"RMSE:\", rmse)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bc265db12c228b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823beec798adab4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vamos a probar con KNN Regresor\n",
    "from sklearn import neighbors\n",
    "from sklearn import metrics\n",
    "regr = neighbors.KNeighborsRegressor()\n",
    "\n",
    "# We train it\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# We obtain predictions on the test set\n",
    "y_test_pred = regr.predict(X_test)\n",
    "\n",
    "# We compute accuracy\n",
    "rmse_knn = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "print(f\"RMSE of the model: {rmse_knn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correlaciones entre parámetros:\n",
    "Al principio, parece que las columnas lai_lv.13 y lai_hv.13 tienen una correlación, pero según avanza el tiempo, desaparece.\n",
    "\n",
    "## Escala de los datos\n",
    "Entre las diferentes columnas de datos, tenemos valores y magnitudes muy dispares."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe1707edb484fdf4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
